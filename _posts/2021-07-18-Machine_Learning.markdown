---
layout: page
title: "Technology Research: Machine Learning"
date: 2021-07-04
permalink: "/Machine_Learning.html"
---


<img src="pic/Machine_learning.jpeg" width="300px">

author: Kim

# What does it do?


Machine learning is a subsection of artificial intelligence (AI), which uses complex algorithms to identify and decipher useful patterns from datasets of information (IBM 2021). Rather than specifically being programmed to sort through the data, machine learning creates a model based on the initial “pre-training data” to predict and decide on tasks (IBM 2021), and for this reason is also known as predictive modelling or predictive analytics. Manually inputting training data refines and improves accuracy of the predictions and tasks (SAS 2021).  

Different types of machine learning algorithms include reinforcement, supervised, semi-supervised, and unsupervised learning (SAS 2021). Supervised learning involves an operator providing the machine a set of data with desired inputs and outputs, and the algorithm must discover a method to correlate the dataset using observations and predictions, which are then corrected by the operator, and this approach repeats until the algorithm increases in accuracy (SAS 2021). Semi-supervised learning is somewhat similar; however the dataset includes labelled and unlabelled data. Labelled data is tagged with meaningful information for the machine to understand, and by using these correlations the algorithm learns how to label the unlabelled data (SAS 2021). Unsupervised learning involves the machine directly identifying patterns and correlations in a large amount of data, gradually improving in accuracy over the course of the process. Due to the sheer amounts of data, it is usually grouped into clusters of similar information which helps the algorithm sort through it (SAS 2021). Reinforcement learning is a different process where the algorithm is provided with an amount of actions, parameters, and end values (Dickson 2021). Within the bounds of the rules, the machine learns to explore different possibilities and options to come to the most optimal solution, essentially learning through trial and error and from past experiences (SAS 2021).

Many of the uses of machine learning technology include playing games, self-driving vehicles, recommending retail products, to medical uses such as the processing of the human genome project (IBM 2021). Current technology in machine learning allows machines to gather data and information unsupervised to find patterns, but is not yet entirely autonomous (SAS 2021).  

While it is simple for humans to analyse and comprehend images and speech, for a machine, processing and understanding this data is complex. Thus, machine learning concepts evolved to utilise artificial neural networks, which are interconnected networks of data inspired by how neurons in a biological brain processes information (Dickson 2021). The neural network technology is used in deep learning, which involves vast amounts of self-improving neural networks that discover patterns automatically instead of having to be provided manually inputted data. Deep learning is used to decipher very complex patterns such as images or speech, and the capacity and capabilities of deep learning will only improve over time with increased computing technology (SAS 2021).

Recent developments in machine learning have allowed for algorithms to be self-supervised in pre-training, which means that algorithm models are self-taught how to process large amounts of pure data, without the need for humans to frequently label inputted data (Tamkin, A 2021). As these developments are still relatively new, the types of methods used are very specific and may not be able to be used on a broad range of applications as of yet. However, potential applications in future projects include astronomy, healthcare, and remote sensing (Tamkin, A 2021), as well as improvement of machine understanding of language and even computer vision in greater complexity (Dickson 2021). For example, algorithms would be able to learn to predict the contents of hidden regions in an image, or decipher missing information from incomplete sentences, which can have a vast range of potential applications (Dickson 2021).



# What is the likely impact?

Machine learning utilises complex algorithms in a large scale to discover useful patterns in data that would otherwise almost be impossible for humans to identify (IBM 2021). With this in mind, machine learning has the potential to improve efficiency in a number of sectors. Already, machine learning applications are used in a broad range of fields including retail, banking, sports, healthcare, and manufacturing (SAS 2021). As the technology improves over time and demand increases for machine learning, there is a belief that it would result in the redundancy of a wide range of jobs currently undertaken by humans (IBM 2021). However, solutions to these concerns need to be considered in each industry involved. An example is in the automotive sector where there is a focus on electric vehicle production to adapt to environmental concerns and initiatives (IBM 2021). Similarly, there will be a need to shift many labour force priorities into programming and technology fields, as machine learning replaces the type of work previously completed by humans. The setting up of and maintenance of reliable and beneficial machine learning still requires human insights and interaction throughout the process (SAS 2021). However, jobs involved in customer service and interactions that are too complex for machine learning to complete independently would remain (IBM 2021).

Applications of AI technologies such as machine learning are likely to be more widespread than, for example, automation of repetitive manual tasks using robotic hardware. Setting up and running machine learning tasks in the background can allow humans to go about other tasks and can improve efficiency through human and machine teamwork. Some examples of machine learning capabilities in the work force include improvement of productivity via prediction of maintenance problems before they will happen, and applications for real-time online pricing (SAS 2021).



# How will this affect you?

In my everyday life and for the people closest to me, I can see that machine learning concepts are already used in applications such as tailoring search engine results, suggestions or recommendations of content in streaming services, social media feeds and online shopping based on previous behaviour, and also in searching for visually similar images in search engines, speech-to-text technology, and even “selfie” filters that analyse facial data to output manipulated images in real-time. It is expected that these algorithms will only become increasingly more commonplace and more involved in our lives over time.

As machine learning technology improves, there may even be more applications for these algorithms to make suggestions, predictions, or solutions, based on data gathered in daily life. The amount of data obtained from the internet of things in the average household and in businesses is sure to increase over time, as there is a heavy reliance on technology such as smartphones and computing devices for communication, productivity, and entertainment (SAS 2021). It is easy to imagine that workplaces would become more reliant on machine learning to streamline labour and business solutions, as well as entertainment technology utilising user data to tailor their products and services.  

And as the technology progresses, information technology education must anticipate for a shift in priorities and job demands of the future and I think that machine learning and AI technology will be at the forefront of future technology, or at the very least, become a major part of it. Because of this, I think that AI technology such as machine learning will be a prominent part of my studies towards a Bachelor of Information Technology, and I will need to learn more and more about it as my studies progress.



# References

SAS 2021, Machine Learning and Artificial Intelligence, SAS Institute, viewed 16 July 2021, < https://www.sas.com/en_au/insights/articles/analytics/machine-learning-and-artificial-intelligence-in-a-brave-new-world.html >.

Dickson, B 2021, ‘The future of deep learning, according to its pioneers’, TechTalks, 1 July, viewed 16 July 2021, < https://bdtechtalks.com/2021/07/01/deep-learning-future-bengio-hinton-lecun >.

IBM 2021, Machine Learning, International Business Machines Corporation, viewed 16 July 2021, < https://www.ibm.com/cloud/learn/machine-learning >.

Tamkin, A 2021, ‘Broadening the Reach of Contrastive Learning with Viewmaker Networks’, blog post, 20 April, viewed 16 July 2021, < https://ai.stanford.edu/blog/viewmaker/ >.
